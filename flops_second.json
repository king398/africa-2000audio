
-------------------------- DeepSpeed Flops Profiler --------------------------
Profile Summary at step 11:
Notations:
data parallel size (dp_size), model parallel size(mp_size),
number of parameters (params), number of multiply-accumulate operations(MACs),
number of floating-point operations (flops), floating-point operations per second (FLOPS),
fwd latency (forward propagation latency), bwd latency (backward propagation latency),
step (weights update latency), iter latency (sum of fwd, bwd and step latency)

world size:                                                   1       
data parallel size:                                           1       
model parallel size:                                          1       
batch size per GPU:                                           6       
params per gpu:                                               222.9 M 
params of model = params per GPU * mp_size:                   222.9 M 
fwd MACs per GPU:                                             665.62 GMACs
fwd flops per GPU:                                            1331.97 G
fwd flops of model = fwd flops per GPU * mp_size:             1331.97 G
fwd latency:                                                  73.2 ms 
fwd FLOPS per GPU = fwd flops per GPU / fwd latency:          18.2 TFLOPS
bwd latency:                                                  72.43 ms
bwd FLOPS per GPU = 2 * fwd flops per GPU / bwd latency:      36.78 TFLOPS
fwd+bwd FLOPS per GPU = 3 * fwd flops per GPU / (fwd+bwd latency):   27.44 TFLOPS
step latency:                                                 50.76 ms
iter latency:                                                 196.39 ms
FLOPS per GPU = 3 * fwd flops per GPU / iter latency:         20.35 TFLOPS
samples/second:                                               30.55   

----------------------------- Aggregated Profile per GPU -----------------------------
Top 1 modules in terms of params, MACs or fwd latency at different model depths:
depth 0:
    params      - {'T5ForConditionalGeneration': '222.9 M'}
    MACs        - {'T5ForConditionalGeneration': '665.62 GMACs'}
    fwd latency - {'T5ForConditionalGeneration': '73.09 ms'}
depth 1:
    params      - {'T5Stack': '247.58 M'}
    MACs        - {'T5Stack': '599.3 GMACs'}
    fwd latency - {'T5Stack': '71.55 ms'}
depth 2:
    params      - {'ModuleList': '198.23 M'}
    MACs        - {'ModuleList': '599.3 GMACs'}
    fwd latency - {'ModuleList': '69.53 ms'}
depth 3:
    params      - {'T5Block': '198.23 M'}
    MACs        - {'T5Block': '599.3 GMACs'}
    fwd latency - {'T5Block': '69.53 ms'}
depth 4:
    params      - {'ModuleList': '198.23 M'}
    MACs        - {'ModuleList': '599.3 GMACs'}
    fwd latency - {'ModuleList': '61.35 ms'}
depth 5:
    params      - {'T5LayerFF': '113.26 M'}
    MACs        - {'T5LayerFF': '304.41 GMACs'}
    fwd latency - {'T5LayerSelfAttention': '31.17 ms'}
depth 6:
    params      - {'T5DenseActDense': '113.25 M'}
    MACs        - {'T5DenseActDense': '304.41 GMACs'}
    fwd latency - {'T5Attention': '36.61 ms'}

------------------------------ Detailed Profile per GPU ------------------------------
Each module profile is listed after its name in the following order: 
params, percentage of total params, MACs, percentage of total MACs, fwd latency, percentage of total fwd latency, fwd FLOPS

Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). They are not counted as submodules, thus not to be printed out. However they make up the difference between a parent's MACs (or latency) and the sum of its submodules'.
2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.
3. The fwd latency listed in the top module's profile is directly captured at the module forward function in PyTorch, thus it's less than the fwd latency shown above which is captured in DeepSpeed.

T5ForConditionalGeneration(
  222.9 M, 100.00% Params, 665.62 GMACs, 100.00% MACs, 73.09 ms, 100.00% latency, 18.22 TFLOPS, 
  (shared): Embedding(24.67 M, 11.07% Params, 0 MACs, 0.00% MACs, 219.58 us, 0.30% latency, 0.0 FLOPS, 32128, 768)
  (encoder): T5Stack(
    109.63 M, 49.18% Params, 250.5 GMACs, 37.63% MACs, 29.68 ms, 40.60% latency, 16.89 TFLOPS, 
    (embed_tokens): Embedding(24.67 M, 11.07% Params, 0 MACs, 0.00% MACs, 219.58 us, 0.30% latency, 0.0 FLOPS, 32128, 768)
    (block): ModuleList(
      (0): T5Block(
        7.08 M, 3.18% Params, 20.88 GMACs, 3.14% MACs, 3.55 ms, 4.86% latency, 11.75 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 2.57 ms, 3.52% latency, 6.38 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 2.13 ms, 2.91% latency, 7.71 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 154.02 us, 0.21% latency, 20.59 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 187.64 us, 0.26% latency, 16.9 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 147.1 us, 0.20% latency, 21.56 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 104.67 us, 0.14% latency, 30.3 TFLOPS, in_features=768, out_features=768, bias=False)
              (relative_attention_bias): Embedding(384, 0.00% Params, 0 MACs, 0.00% MACs, 61.99 us, 0.08% latency, 0.0 FLOPS, 32, 12)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 315.67 us, 0.43% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 46.73 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 700.95 us, 0.96% latency, 36.2 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 460.62 us, 0.63% latency, 55.09 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 146.63 us, 0.20% latency, 86.5 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 139.47 us, 0.19% latency, 90.94 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 55.31 us, 0.08% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 63.18 us, 0.09% latency, 130.7 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 122.79 us, 0.17% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 49.11 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (1): T5Block(
        7.08 M, 3.18% Params, 20.88 GMACs, 3.14% MACs, 2.21 ms, 3.02% latency, 18.93 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.27 ms, 1.74% latency, 12.91 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.03 ms, 1.41% latency, 15.87 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 95.84 us, 0.13% latency, 33.08 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 85.59 us, 0.12% latency, 37.05 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 87.02 us, 0.12% latency, 36.44 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 97.04 us, 0.13% latency, 32.68 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 118.97 us, 0.16% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 46.73 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 685.93 us, 0.94% latency, 36.99 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 446.8 us, 0.61% latency, 56.79 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 142.81 us, 0.20% latency, 88.81 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 136.85 us, 0.19% latency, 92.68 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 55.55 us, 0.08% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 55.55 us, 0.08% latency, 148.65 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 119.92 us, 0.16% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 50.07 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (2): T5Block(
        7.08 M, 3.18% Params, 20.88 GMACs, 3.14% MACs, 2.13 ms, 2.92% latency, 19.59 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.23 ms, 1.68% latency, 13.36 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 973.46 us, 1.33% latency, 16.84 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 92.03 us, 0.13% latency, 34.46 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 84.88 us, 0.12% latency, 37.36 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 83.92 us, 0.11% latency, 37.78 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 97.04 us, 0.13% latency, 32.68 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 133.28 us, 0.18% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 45.78 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 674.49 us, 0.92% latency, 37.62 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 433.92 us, 0.59% latency, 58.48 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 141.14 us, 0.19% latency, 89.86 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 132.32 us, 0.18% latency, 95.85 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 54.6 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 49.59 us, 0.07% latency, 166.51 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 124.93 us, 0.17% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 47.92 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (3): T5Block(
        7.08 M, 3.18% Params, 20.88 GMACs, 3.14% MACs, 2.18 ms, 2.98% latency, 19.19 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.24 ms, 1.70% latency, 13.18 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.01 ms, 1.38% latency, 16.27 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 93.94 us, 0.13% latency, 33.76 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 96.32 us, 0.13% latency, 32.92 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 90.6 us, 0.12% latency, 35.0 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 95.37 us, 0.13% latency, 33.25 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 121.36 us, 0.17% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 44.82 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 700.47 us, 0.96% latency, 36.23 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 446.8 us, 0.61% latency, 56.79 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 147.58 us, 0.20% latency, 85.94 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 131.85 us, 0.18% latency, 96.2 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 57.94 us, 0.08% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 53.17 us, 0.07% latency, 155.31 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 133.04 us, 0.18% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 48.64 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (4): T5Block(
        7.08 M, 3.18% Params, 20.88 GMACs, 3.14% MACs, 2.24 ms, 3.06% latency, 18.67 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.26 ms, 1.72% latency, 13.03 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.0 ms, 1.37% latency, 16.33 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 97.51 us, 0.13% latency, 32.52 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 82.73 us, 0.11% latency, 38.33 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 80.59 us, 0.11% latency, 39.35 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 114.92 us, 0.16% latency, 27.59 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 117.78 us, 0.16% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 57.7 us, 0.08% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 710.25 us, 0.97% latency, 35.73 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 431.54 us, 0.59% latency, 58.8 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 138.52 us, 0.19% latency, 91.56 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 131.61 us, 0.18% latency, 96.37 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 54.36 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 48.64 us, 0.07% latency, 169.78 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 159.03 us, 0.22% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 47.68 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (5): T5Block(
        7.08 M, 3.18% Params, 20.88 GMACs, 3.14% MACs, 2.09 ms, 2.86% latency, 19.97 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.2 ms, 1.64% latency, 13.68 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 966.07 us, 1.32% latency, 16.97 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 92.03 us, 0.13% latency, 34.46 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 83.68 us, 0.11% latency, 37.89 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 81.3 us, 0.11% latency, 39.0 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 97.27 us, 0.13% latency, 32.6 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 114.92 us, 0.16% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 45.54 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 659.23 us, 0.90% latency, 38.49 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 425.82 us, 0.58% latency, 59.59 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 137.57 us, 0.19% latency, 92.2 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 128.75 us, 0.18% latency, 98.52 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 55.31 us, 0.08% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 49.11 us, 0.07% latency, 168.13 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 117.3 us, 0.16% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 47.45 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (6): T5Block(
        7.08 M, 3.18% Params, 20.88 GMACs, 3.14% MACs, 3.32 ms, 4.54% latency, 12.58 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.26 ms, 1.73% latency, 12.96 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.02 ms, 1.39% latency, 16.13 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 116.11 us, 0.16% latency, 27.31 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 91.31 us, 0.12% latency, 34.73 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 83.21 us, 0.11% latency, 38.11 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 95.13 us, 0.13% latency, 33.33 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 112.53 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 53.64 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 665.9 us, 0.91% latency, 38.11 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 429.15 us, 0.59% latency, 59.13 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 137.57 us, 0.19% latency, 92.2 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 133.51 us, 0.18% latency, 95.0 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 55.79 us, 0.08% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 48.16 us, 0.07% latency, 171.46 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 119.21 us, 0.16% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 49.83 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (7): T5Block(
        7.08 M, 3.18% Params, 20.88 GMACs, 3.14% MACs, 2.08 ms, 2.85% latency, 20.05 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.2 ms, 1.65% latency, 13.61 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 963.93 us, 1.32% latency, 17.01 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 93.46 us, 0.13% latency, 33.93 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 82.49 us, 0.11% latency, 38.44 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 81.3 us, 0.11% latency, 39.0 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 101.8 us, 0.14% latency, 31.15 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 120.64 us, 0.17% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 47.45 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 654.94 us, 0.90% latency, 38.74 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 421.05 us, 0.58% latency, 60.27 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 138.76 us, 0.19% latency, 91.41 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 133.04 us, 0.18% latency, 95.34 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 52.93 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 45.78 us, 0.06% latency, 180.39 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 114.68 us, 0.16% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 49.83 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (8): T5Block(
        7.08 M, 3.18% Params, 20.88 GMACs, 3.14% MACs, 2.38 ms, 3.26% latency, 17.55 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.47 ms, 2.02% latency, 11.13 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.23 ms, 1.68% latency, 13.33 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 91.55 us, 0.13% latency, 34.63 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 82.02 us, 0.11% latency, 38.66 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 79.87 us, 0.11% latency, 39.7 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 96.8 us, 0.13% latency, 32.76 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 125.41 us, 0.17% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 47.45 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 671.39 us, 0.92% latency, 37.8 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 428.92 us, 0.59% latency, 59.16 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 139.24 us, 0.19% latency, 91.09 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 131.37 us, 0.18% latency, 96.55 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 53.64 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 48.88 us, 0.07% latency, 168.95 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 126.12 us, 0.17% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 46.97 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (9): T5Block(
        7.08 M, 3.18% Params, 20.88 GMACs, 3.14% MACs, 2.1 ms, 2.88% latency, 19.85 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.21 ms, 1.66% latency, 13.51 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 967.74 us, 1.32% latency, 16.94 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 92.98 us, 0.13% latency, 34.1 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 83.68 us, 0.11% latency, 37.89 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 81.06 us, 0.11% latency, 39.12 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 97.75 us, 0.13% latency, 32.44 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 126.36 us, 0.17% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 47.21 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 657.8 us, 0.90% latency, 38.58 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 434.4 us, 0.59% latency, 58.42 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 139.71 us, 0.19% latency, 90.78 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 132.08 us, 0.18% latency, 96.03 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 53.64 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 53.17 us, 0.07% latency, 155.31 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 106.81 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 48.64 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (10): T5Block(
        7.08 M, 3.18% Params, 20.88 GMACs, 3.14% MACs, 2.08 ms, 2.84% latency, 20.09 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.19 ms, 1.63% latency, 13.74 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 962.97 us, 1.32% latency, 17.03 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 91.55 us, 0.13% latency, 34.63 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 87.74 us, 0.12% latency, 36.14 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 80.59 us, 0.11% latency, 39.35 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 93.94 us, 0.13% latency, 33.76 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 112.3 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 46.01 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 653.27 us, 0.89% latency, 38.84 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 424.62 us, 0.58% latency, 59.76 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 138.04 us, 0.19% latency, 91.88 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 130.41 us, 0.18% latency, 97.26 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 53.88 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 47.68 us, 0.07% latency, 173.17 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 110.63 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 48.88 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (11): T5Block(
        7.08 M, 3.18% Params, 20.88 GMACs, 3.14% MACs, 2.11 ms, 2.89% latency, 19.76 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.21 ms, 1.66% latency, 13.54 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 976.09 us, 1.34% latency, 16.8 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 89.88 us, 0.12% latency, 35.28 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 81.54 us, 0.11% latency, 38.89 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 90.12 us, 0.12% latency, 35.18 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 94.65 us, 0.13% latency, 33.5 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 116.35 us, 0.16% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 45.3 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 652.07 us, 0.89% latency, 38.91 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 425.34 us, 0.58% latency, 59.66 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 139.0 us, 0.19% latency, 91.25 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 130.65 us, 0.18% latency, 97.08 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 53.64 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 48.4 us, 0.07% latency, 170.61 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 109.67 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 47.92 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
    )
    (final_layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 127.55 us, 0.17% latency, 0.0 FLOPS, )
    (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 136.61 us, 0.19% latency, 0.0 FLOPS, p=0.1, inplace=False)
  )
  (decoder): T5Stack(
    137.95 M, 61.89% Params, 348.8 GMACs, 52.40% MACs, 41.88 ms, 57.30% latency, 16.67 TFLOPS, 
    (embed_tokens): Embedding(24.67 M, 11.07% Params, 0 MACs, 0.00% MACs, 219.58 us, 0.30% latency, 0.0 FLOPS, 32128, 768)
    (block): ModuleList(
      (0): T5Block(
        9.44 M, 4.23% Params, 29.07 GMACs, 4.37% MACs, 3.81 ms, 5.21% latency, 15.27 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.53 ms, 2.09% latency, 10.74 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.28 ms, 1.75% latency, 12.81 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 93.7 us, 0.13% latency, 33.84 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 84.88 us, 0.12% latency, 37.36 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 83.21 us, 0.11% latency, 38.11 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 96.8 us, 0.13% latency, 32.76 TFLOPS, in_features=768, out_features=768, bias=False)
              (relative_attention_bias): Embedding(384, 0.00% Params, 0 MACs, 0.00% MACs, 55.07 us, 0.08% latency, 0.0 FLOPS, 32, 12)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 126.12 us, 0.17% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 45.78 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.25 ms, 1.71% latency, 13.09 TFLOPS, 
            (EncDecAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.02 ms, 1.40% latency, 16.07 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 93.46 us, 0.13% latency, 33.93 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 98.94 us, 0.14% latency, 32.05 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 105.14 us, 0.14% latency, 30.16 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 94.89 us, 0.13% latency, 33.42 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 105.62 us, 0.14% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 52.69 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 659.47 us, 0.90% latency, 38.48 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 429.15 us, 0.59% latency, 59.13 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 138.52 us, 0.19% latency, 91.56 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 131.85 us, 0.18% latency, 96.2 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 54.12 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 50.31 us, 0.07% latency, 164.15 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 115.39 us, 0.16% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 47.68 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (1): T5Block(
        9.44 M, 4.23% Params, 29.07 GMACs, 4.37% MACs, 3.37 ms, 4.62% latency, 17.24 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.2 ms, 1.65% latency, 13.62 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 972.27 us, 1.33% latency, 16.87 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 92.51 us, 0.13% latency, 34.28 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 83.68 us, 0.11% latency, 37.89 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 82.02 us, 0.11% latency, 38.66 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 95.84 us, 0.13% latency, 33.08 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 114.44 us, 0.16% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 45.3 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.16 ms, 1.59% latency, 14.15 TFLOPS, 
            (EncDecAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 936.75 us, 1.28% latency, 17.5 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 90.12 us, 0.12% latency, 35.18 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 82.73 us, 0.11% latency, 38.33 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 89.65 us, 0.12% latency, 35.37 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 96.56 us, 0.13% latency, 32.84 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 107.53 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 44.11 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 663.28 us, 0.91% latency, 38.26 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 431.06 us, 0.59% latency, 58.87 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 139.95 us, 0.19% latency, 90.63 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 133.75 us, 0.18% latency, 94.83 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 54.6 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 48.64 us, 0.07% latency, 169.78 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 111.1 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 49.11 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (2): T5Block(
        9.44 M, 4.23% Params, 29.07 GMACs, 4.37% MACs, 3.35 ms, 4.58% latency, 17.39 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.2 ms, 1.64% latency, 13.69 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 969.41 us, 1.33% latency, 16.91 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 92.03 us, 0.13% latency, 34.46 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 83.68 us, 0.11% latency, 37.89 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 80.35 us, 0.11% latency, 39.46 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 96.56 us, 0.13% latency, 32.84 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 111.34 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 47.68 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.16 ms, 1.59% latency, 14.11 TFLOPS, 
            (EncDecAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 927.69 us, 1.27% latency, 17.68 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 91.31 us, 0.12% latency, 34.73 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 83.68 us, 0.11% latency, 37.89 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 81.3 us, 0.11% latency, 39.0 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 96.56 us, 0.13% latency, 32.84 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 108.24 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 45.78 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 655.17 us, 0.90% latency, 38.73 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 429.39 us, 0.59% latency, 59.1 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 137.57 us, 0.19% latency, 92.2 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 131.85 us, 0.18% latency, 96.2 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 54.36 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 50.78 us, 0.07% latency, 162.6 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 108.24 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 50.07 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (3): T5Block(
        9.44 M, 4.23% Params, 29.07 GMACs, 4.37% MACs, 3.4 ms, 4.65% latency, 17.13 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.23 ms, 1.69% latency, 13.31 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.0 ms, 1.37% latency, 16.33 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 91.55 us, 0.13% latency, 34.63 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 92.03 us, 0.13% latency, 34.46 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 88.21 us, 0.12% latency, 35.95 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 96.32 us, 0.13% latency, 32.92 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 113.25 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 44.82 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.16 ms, 1.59% latency, 14.1 TFLOPS, 
            (EncDecAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 924.35 us, 1.26% latency, 17.74 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 91.31 us, 0.12% latency, 34.73 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 84.16 us, 0.12% latency, 37.68 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 82.49 us, 0.11% latency, 38.44 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 95.61 us, 0.13% latency, 33.17 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 119.69 us, 0.16% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 45.54 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 662.57 us, 0.91% latency, 38.3 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 435.35 us, 0.60% latency, 58.29 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 139.0 us, 0.19% latency, 91.25 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 134.71 us, 0.18% latency, 94.16 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 59.84 us, 0.08% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 47.92 us, 0.07% latency, 172.31 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 109.91 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 47.45 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (4): T5Block(
        9.44 M, 4.23% Params, 29.07 GMACs, 4.37% MACs, 3.4 ms, 4.65% latency, 17.13 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.2 ms, 1.65% latency, 13.62 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 976.56 us, 1.34% latency, 16.79 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 91.79 us, 0.13% latency, 34.54 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 83.92 us, 0.11% latency, 37.78 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 81.78 us, 0.11% latency, 38.77 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 95.84 us, 0.13% latency, 33.08 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 112.06 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 45.54 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.19 ms, 1.63% latency, 13.75 TFLOPS, 
            (EncDecAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 929.12 us, 1.27% latency, 17.65 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 93.46 us, 0.13% latency, 33.93 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 83.68 us, 0.11% latency, 37.89 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 80.82 us, 0.11% latency, 39.23 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 97.99 us, 0.13% latency, 32.36 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 143.29 us, 0.20% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 45.54 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 661.61 us, 0.91% latency, 38.35 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 430.11 us, 0.59% latency, 59.0 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 139.95 us, 0.19% latency, 90.63 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 132.32 us, 0.18% latency, 95.85 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 54.6 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 48.88 us, 0.07% latency, 168.95 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 114.92 us, 0.16% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 49.59 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (5): T5Block(
        9.44 M, 4.23% Params, 29.07 GMACs, 4.37% MACs, 3.38 ms, 4.62% latency, 17.22 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.21 ms, 1.65% latency, 13.56 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 977.99 us, 1.34% latency, 16.77 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 97.27 us, 0.13% latency, 32.6 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 84.16 us, 0.12% latency, 37.68 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 88.93 us, 0.12% latency, 35.66 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 93.94 us, 0.13% latency, 33.76 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 116.59 us, 0.16% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 44.82 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.16 ms, 1.58% latency, 14.19 TFLOPS, 
            (EncDecAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 922.68 us, 1.26% latency, 17.77 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 90.36 us, 0.12% latency, 35.09 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 82.73 us, 0.11% latency, 38.33 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 79.63 us, 0.11% latency, 39.82 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 92.51 us, 0.13% latency, 34.28 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 117.3 us, 0.16% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 43.63 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 663.76 us, 0.91% latency, 38.23 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 433.92 us, 0.59% latency, 58.48 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 139.0 us, 0.19% latency, 91.25 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 130.41 us, 0.18% latency, 97.26 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 54.12 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 56.27 us, 0.08% latency, 146.76 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 117.54 us, 0.16% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 49.59 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (6): T5Block(
        9.44 M, 4.23% Params, 29.07 GMACs, 4.37% MACs, 3.4 ms, 4.65% latency, 17.11 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.18 ms, 1.62% latency, 13.88 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 955.1 us, 1.31% latency, 17.17 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 92.03 us, 0.13% latency, 34.46 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 82.97 us, 0.11% latency, 38.22 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 81.78 us, 0.11% latency, 38.77 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 95.61 us, 0.13% latency, 33.17 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 111.82 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 43.15 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.2 ms, 1.64% latency, 13.66 TFLOPS, 
            (EncDecAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 942.71 us, 1.29% latency, 17.39 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 93.7 us, 0.13% latency, 33.84 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 81.78 us, 0.11% latency, 38.77 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 79.15 us, 0.11% latency, 40.06 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 94.41 us, 0.13% latency, 33.59 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 137.33 us, 0.19% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 45.06 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 661.13 us, 0.90% latency, 38.38 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 422.95 us, 0.58% latency, 60.0 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 138.28 us, 0.19% latency, 91.72 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 130.41 us, 0.18% latency, 97.26 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 52.45 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 48.4 us, 0.07% latency, 170.61 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 124.93 us, 0.17% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 47.21 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (7): T5Block(
        9.44 M, 4.23% Params, 29.07 GMACs, 4.37% MACs, 3.35 ms, 4.58% latency, 17.38 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.2 ms, 1.65% latency, 13.64 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 960.83 us, 1.31% latency, 17.07 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 91.08 us, 0.12% latency, 34.82 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 82.49 us, 0.11% latency, 38.44 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 80.35 us, 0.11% latency, 39.46 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 94.89 us, 0.13% latency, 33.42 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 128.98 us, 0.18% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 43.39 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.13 ms, 1.55% latency, 14.52 TFLOPS, 
            (EncDecAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 907.18 us, 1.24% latency, 18.08 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 90.84 us, 0.12% latency, 34.91 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 83.68 us, 0.11% latency, 37.89 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 79.63 us, 0.11% latency, 39.82 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 94.65 us, 0.13% latency, 33.5 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 106.1 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 44.58 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 670.91 us, 0.92% latency, 37.82 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 424.86 us, 0.58% latency, 59.73 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 137.33 us, 0.19% latency, 92.36 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 130.89 us, 0.18% latency, 96.9 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 54.84 us, 0.08% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 48.64 us, 0.07% latency, 169.78 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 126.36 us, 0.17% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 51.74 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (8): T5Block(
        9.44 M, 4.23% Params, 29.07 GMACs, 4.37% MACs, 3.35 ms, 4.58% latency, 17.38 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.19 ms, 1.63% latency, 13.73 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 962.26 us, 1.32% latency, 17.04 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 90.6 us, 0.12% latency, 35.0 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 80.35 us, 0.11% latency, 39.46 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 80.35 us, 0.11% latency, 39.46 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 94.65 us, 0.13% latency, 33.5 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 119.45 us, 0.16% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 45.06 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.16 ms, 1.59% latency, 14.1 TFLOPS, 
            (EncDecAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 939.85 us, 1.29% latency, 17.45 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 89.88 us, 0.12% latency, 35.28 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 82.49 us, 0.11% latency, 38.44 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 80.11 us, 0.11% latency, 39.58 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 93.7 us, 0.13% latency, 33.84 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 107.53 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 44.82 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 658.27 us, 0.90% latency, 38.55 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 432.01 us, 0.59% latency, 58.74 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 137.09 us, 0.19% latency, 92.52 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 133.28 us, 0.18% latency, 95.17 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 55.55 us, 0.08% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 51.98 us, 0.07% latency, 158.87 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 108.96 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 49.83 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (9): T5Block(
        9.44 M, 4.23% Params, 29.07 GMACs, 4.37% MACs, 3.41 ms, 4.66% latency, 17.07 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.25 ms, 1.70% latency, 13.17 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.02 ms, 1.40% latency, 16.06 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 90.84 us, 0.12% latency, 34.91 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 92.74 us, 0.13% latency, 34.19 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 87.74 us, 0.12% latency, 36.14 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 98.47 us, 0.13% latency, 32.2 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 111.58 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 44.35 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.16 ms, 1.58% latency, 14.16 TFLOPS, 
            (EncDecAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 926.02 us, 1.27% latency, 17.71 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 90.84 us, 0.12% latency, 34.91 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 82.97 us, 0.11% latency, 38.22 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 81.06 us, 0.11% latency, 39.12 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 98.47 us, 0.13% latency, 32.2 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 111.1 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 47.68 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 671.86 us, 0.92% latency, 37.77 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 440.84 us, 0.60% latency, 57.56 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 151.16 us, 0.21% latency, 83.91 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 132.56 us, 0.18% latency, 95.68 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 54.84 us, 0.08% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 48.88 us, 0.07% latency, 168.95 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 112.3 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 48.4 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (10): T5Block(
        9.44 M, 4.23% Params, 29.07 GMACs, 4.37% MACs, 3.4 ms, 4.65% latency, 17.11 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.19 ms, 1.63% latency, 13.8 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 961.54 us, 1.32% latency, 17.05 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 93.94 us, 0.13% latency, 33.76 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 84.64 us, 0.12% latency, 37.46 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 83.21 us, 0.11% latency, 38.11 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 96.56 us, 0.13% latency, 32.84 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 111.58 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 45.78 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.21 ms, 1.66% latency, 13.54 TFLOPS, 
            (EncDecAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 978.47 us, 1.34% latency, 16.76 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 106.33 us, 0.15% latency, 29.82 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 89.65 us, 0.12% latency, 35.37 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 81.3 us, 0.11% latency, 39.0 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 96.32 us, 0.13% latency, 32.92 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 114.68 us, 0.16% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 46.01 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 660.42 us, 0.90% latency, 38.42 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 428.44 us, 0.59% latency, 59.23 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 138.52 us, 0.19% latency, 91.56 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 134.71 us, 0.18% latency, 94.16 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 52.21 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 49.35 us, 0.07% latency, 167.32 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 114.68 us, 0.16% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 48.64 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
      (11): T5Block(
        9.44 M, 4.23% Params, 29.07 GMACs, 4.37% MACs, 3.44 ms, 4.71% latency, 16.89 TFLOPS, 
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.26 ms, 1.72% latency, 13.02 TFLOPS, 
            (SelfAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.02 ms, 1.40% latency, 16.01 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 92.98 us, 0.13% latency, 34.1 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 82.73 us, 0.11% latency, 38.33 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 99.42 us, 0.14% latency, 31.89 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 94.41 us, 0.13% latency, 33.59 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 114.44 us, 0.16% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 48.88 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 1.19 ms, 1.63% latency, 13.76 TFLOPS, 
            (EncDecAttention): T5Attention(
              2.36 M, 1.06% Params, 8.19 GMACs, 1.23% MACs, 958.92 us, 1.31% latency, 17.1 TFLOPS, 
              (q): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 92.74 us, 0.13% latency, 34.19 TFLOPS, in_features=768, out_features=768, bias=False)
              (k): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 84.88 us, 0.12% latency, 37.36 TFLOPS, in_features=768, out_features=768, bias=False)
              (v): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 91.08 us, 0.12% latency, 34.82 TFLOPS, in_features=768, out_features=768, bias=False)
              (o): Linear(589.82 k, 0.26% Params, 1.59 GMACs, 0.24% MACs, 102.28 us, 0.14% latency, 31.0 TFLOPS, in_features=768, out_features=768, bias=False)
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 112.3 us, 0.15% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 45.54 us, 0.06% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 658.99 us, 0.90% latency, 38.51 TFLOPS, 
            (DenseReluDense): T5DenseActDense(
              4.72 M, 2.12% Params, 12.68 GMACs, 1.91% MACs, 426.05 us, 0.58% latency, 59.56 TFLOPS, 
              (wi): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 139.24 us, 0.19% latency, 91.09 TFLOPS, in_features=768, out_features=3072, bias=False)
              (wo): Linear(2.36 M, 1.06% Params, 6.34 GMACs, 0.95% MACs, 130.41 us, 0.18% latency, 97.26 TFLOPS, in_features=3072, out_features=768, bias=False)
              (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 55.07 us, 0.08% latency, 0.0 FLOPS, p=0.1, inplace=False)
              (act): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 48.4 us, 0.07% latency, 170.61 GFLOPS, )
            )
            (layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 119.45 us, 0.16% latency, 0.0 FLOPS, )
            (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 47.68 us, 0.07% latency, 0.0 FLOPS, p=0.1, inplace=False)
          )
        )
      )
    )
    (final_layer_norm): T5LayerNorm(768, 0.00% Params, 0 MACs, 0.00% MACs, 128.03 us, 0.18% latency, 0.0 FLOPS, )
    (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 116.11 us, 0.16% latency, 0.0 FLOPS, p=0.1, inplace=False)
  )
  (lm_head): Linear(24.67 M, 11.07% Params, 66.32 GMACs, 9.96% MACs, 906.94 us, 1.24% latency, 146.26 TFLOPS, in_features=768, out_features=32128, bias=False)
)
------------------------------------------------------------------------------
